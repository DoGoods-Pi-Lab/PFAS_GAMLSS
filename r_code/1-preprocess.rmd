---
title: "MMIP_PFAS-bs"
author: "Rebekah Petroff"
date: "6/30/2021"
output: html_document
---

## Code for modeling
Adapted from Jackie to assess the association between DNA methylation (outcome = methylation level at each
CpG site, one by one) and exposure of interest, adjusting for any covariates/confounder necessary. There are two places that are "hands-on" if you want - dropping bad samples at the beginning (chunk near line 158) and then dropping bad duplicates before randomly selecting one (chunk at line 405). You can edit these accordingly, or comment out and just let automatic cutoffs do the work.



NOTE: Before starting, make sure your desired pheno file is in the main folder you are rooting into.

Last update: - finished after the first processing, knitted version not created; not enough memory on my computer to process as one swipe 7/16/2021

---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_knit$set(root.dir = normalizePath("L:/MMIP EPIC/PFAS/idat"), echo=FALSE) #change this for your own 

#below is code for installing biocmanager if nec
#if (!requireNamespace("BiocManager", quietly = TRUE))
#install.packages("BiocManager")
#BiocManager::install(version = "3.10") #may need to update this version
#BiocManager::install(c("lumi","ChAMP","FlowSorted.CordBlood.450k","IlluminaHumanMethylationEPICmanifest"))
#BiocManager::install("Enmix")
#BiocManager::install("DMRcate")
#BiocManager::install("minfi")
library(minfi)
library(IlluminaHumanMethylationEPICmanifest)
library(FlowSorted.CordBlood.450k)
library(lumi) ##only using this for a few graphical functions
library(ChAMP) #not working because aof geneLenDataBase
library(missMethyl) 
library(ENmix)
library(car)
library(tidyverse)
library(data.table)


#for cross reactive probes: 
#install.packages("remotes")
#remotes::install_github("markgene/maxprobes")
library(maxprobes)
```

```{r working dir, include =FALSE}
base.dir<-paste(getwd())
```



# Initial Quality Checks

After making sure we have the correct pheno file, we can look at what we have and have to think about for QC. 


```{r Read in phenotype file that will link raw image files to sample IDs and other information, echo=FALSE}
##Make a phenotype file for all rounds combined before doing this
mytargets<-read.metharray.sheet(base.dir, recursive = FALSE)

summary(factor(mytargets$Treatment)) 

```

This pheno sheet contains 195 rows of bisulfite converted EPIC samples from MMIP. 


```{r checking duplicates, echo=FALSE}
print(mytargets$barcode[duplicated(mytargets$barcode)]) #check to make sure each row is unique
summary(factor(mytargets$EPIC_dup)) 
print(mytargets$FamilyID[duplicated(mytargets$FamilyID)]) 

dup_fam<-mytargets$FamilyID[duplicated(mytargets$FamilyID)]
```

There are no duplicated rows (see the character 0) but we do have  familes that have duplicated samples - most were round 1 and 2 duplications, 1 was round 3. The family IDs are printed above. These are saved as a seperate list, so we can randomly choose one that passes QC to include in our final analysis. 



```{r, Read in raw image data files and link to phenotype data, warning = FALSE, include=FALSE}
RGSet<-read.metharray.exp(base = base.dir, targets = mytargets, extended = TRUE, recursive = FALSE, verbose = TRUE, force = TRUE)
#extended reads older program numbers (NEEDS TO BE TRUE FOR ENMIX) 
#force forces them to go together, even though they were different versions
#recursive searches all files in base dir instead of subfiles (false; true searches subfiles)
#this step can take a while, so best to not rerun if not necessary


RGSet ##See what this object is like
```


```{r, Quality Control #1, include=FALSE}
#from minfi (still worthwhile to do - ENmix does not do all of this)

###Create pdf to summarize data at control probes included on each BeadChip. Set sample group as by sex here
###MAKE SURE CREATE OUTPUT FOLDER FIRST
qcReport(RGSet, sampNames=mytargets$Sample_Name, sampGroups=mytargets$sex, pdf="../PFAS_bs/preprocess_output/qcReport",
         maxSamplesPerPage = 24, 
         controls=c("BISULFITE CONVERSION I", "BISULFITE CONVERSION II", "EXTENSION", "HYBRIDIZATION", "NON-POLYMORPHIC", "SPECIFICITY I", "SPECIFICITY II", "TARGET REMOVAL"))
#can be used to make sure no sample looks totally different from the rest of the samples, step 1 of many for QC
```

Checking our predicted sex we can see the following families do not have the correctly predicted sex.


```{r, Quality Control -predicted sex, redo, echo=FALSE}
#Create a methylset object with the raw data for further quality control testing
mset<-preprocessRaw(RGSet)

#Do some of the qc functions in minfiQC
qcout<-minfiQC(mset, fixOutliers=TRUE)
write.csv(qcout$qc, "../PFAS_bs/preprocess_output/QCMinfi.csv", row.names=TRUE)


#Compare to recorded sex
qc_sex<-as.data.frame(qcout$qc$predictedSex) #extract predicted sex
colnames(qc_sex)<-"PredictedSex"
qc_sex$PredictSex<-ifelse(qc_sex$PredictedSex=="M", 0, 1) #convert to numeric values


mytargets$sex_predictFAIL<-mytargets$sex-qc_sex$PredictSex #find nonmatches
length(which(mytargets$sex_predictFAIL!=0)) #a total of 13 samples do match predicted sex

failed_qc<- rbind(mytargets[which(mytargets$sex_predictFAIL!=0),]
                  )#maybe more later

print(nrow(failed_qc)) #total number of failed samples so far
print(failed_qc$FamilyID) #here are their exact family numbers 
```


After loading the files, the first check is checking QC. Below are the first two figures showing the methtylated and unmethylated data to examine outliers, including by sex.


```{r, Quality Control Figures, warning=FALSE,echo=FALSE}
#Compare median intensities in methylated and unmethylated channels to look for major outliers
tiff("../PFAS_bs/preprocess_output/QCplot.tiff", width =6, height = 6, units = 'in', res = 300)
plotQC(qcout$qc)  # Make plot
dev.off()

tiff("../PFAS_bs/preprocess_output/Sexplot.tiff", width = 6, height = 6, units = 'in', res = 300)
plotSex(qcout$object)
dev.off()

plotQC(qcout$qc)

plotSex(qcout$object)
```



All of the samples look pretty good. There some slight outliers in the male/female graph.


```{r,QC and pre-processing with ENMix pipeline, include=FALSE}
setwd("L:/MMIP EPIC/PFAS/PFAS_bs/preprocess_output/")

####as from Xu et al. 2017
qcE<-QCinfo(RGSet, detPthre=1e-16, detPtype="negative", nbthre=3, samplethre=0.05,
            CpGthre=0.05, outlier=TRUE, distplot=TRUE)
##^for this, significant p-value compared to background. sig ones are dropped b/c too similar to regular background; 
##coverage minimum of 3 beads
##5% of probes or CpG failed, drop em
##outliers flagged, renamed as this variable
print(qcE$badsample)#See what the flagged bad samples are

failed_qc_tot<- rbind(failed_qc, 
                  mytargets[which(mytargets$barcode %in% qcE$badsample),])#add to the list of samples to remove

length (qcE$badCpG) # # of CpG sites failing QC
qcE$outlier_sample #aSee the flagged outlier sample
#nothing to add to our list of failed samples

###Based on this and minif QC, we need to exclude some bad samples from downstream analyses. Also exclude the sample that sex match up (see all samples in the failed qc, 13 in total)

#drop family ids that were bad from the get-go
#this was kept in from jackies "bad sample" list
failed_qc_tot<-rbind(failed_qc_tot,
                mytargets[which(mytargets$FamilyID=="59"),], 
                mytargets[mytargets$FamilyID=="116",],               
                mytargets[mytargets$FamilyID=="34",], 
                mytargets[mytargets$FamilyID=="73",], 
                mytargets[mytargets$FamilyID=="110",], 
                mytargets[mytargets$FamilyID=="112",], 
                mytargets[mytargets$FamilyID=="130",], 
                mytargets[mytargets$FamilyID=="138",],
                mytargets[mytargets$FamilyID=="115",],
                mytargets[mytargets$FamilyID=="35",],
                mytargets[mytargets$FamilyID=="126",]
                )
```


Based on this QC, 4 more samples were bad, and 31434 CpGs were dropped. In total, the following families will be removed from the data analysis (before selecting any duplicates).


```{r print bad samples, echo=FALSE}
unique(failed_qc_tot$FamilyID)
length(unique(failed_qc_tot$FamilyID))
length(unique(failed_qc$FamilyID))
```


```{r remove flagged QC and run ENmix processing, warning=FALSE, include=FALSE}
##Drop bad CpG sites in this step too.
id_failqc<-failed_qc_tot$barcode #pull out barcodes of failed samples for the next step
write.csv(failed_qc_tot,"../PFAS_bs/preprocess_output/failed_qc.csv", row.names=TRUE)

####Perform background correction with oob and dye correction with RELIC and drop bad probes here
mdat<-preprocessENmix(RGSet, bgParaEst = "oob", dyeCorr="RELIC", QCinfo=qcE, exQCsample=FALSE, exQCcpg=TRUE,
                      exSample=id_failqc, exCpG=NULL, nCores = 6) #be sure to make your list and have your computer's cores identified in this step

mdat 
#exID above is the own list of samples that didn't make predcited sex
#also dropped probes based on results from the Enmix above 
#this results in 39 dropped samples (21 families) and 31,434 removed probes


#set aside phenotype
pheno<-mdat@colData
colnames(pheno)
dim(pheno) 

#####Set aside SNP control probes - can compare these later on to make sure replicates match
SNP65<-getSnpBeta(RGSet)
SNP65t<-t(SNP65)
dim(SNP65t)
write.csv(SNP65t,"../PFAS_bs/preprocess_output/SNP65.csv", row.names=TRUE)
```


After dropping samples, we can generate variables used to estimate celltypes and surrogate variables. Finally, we can look at our betas to make sure that there are no extreme outliers.


```{r, cell type proportion estimate, adding to the adjustments, include=FALSE}
##estimate the cell type proportions from Bakulski et al. cord blood reference set; with defaults otherwise
#This takes a while to run sometimes!
celltype<-estimateCellProp(RGSet,refdata="FlowSorted.CordBlood.450k",
                 cellTypes=NULL,nonnegative = TRUE,nProbes=50,
                 normalize=TRUE,refplot=FALSE)
summary(celltype)#check distribution of each cell type
write.csv(celltype, "../PFAS_bs/preprocess_output/Celltypes.csv", row.names=TRUE)


##SVA (surrogate variable analysis) is in the ENmix package - this depends on the RGSet because it uses the control probes
### Here we are generating surrogate variables that explain a % of the data variation in the control probes (tech variation)
sva<-ctrlsva(RGSet,percvar=0.9,npc=1,flag=1)
colnames(sva)
#I will need to see if these associate with my other covariates, etc. and adjust for them if they are confounders
#Thus, I want them in the phenotype file and will save just in case, too
write.csv(sva, "../PFAS_bs/preprocess_output/SVA-PCs.csv", row.names=TRUE)


####We need to add the cell types and the SVA PCs to the pheno file so we can use those variables later-
svacell<-cbind(sva,celltype[,-1])#append this to SVA
colnames(svacell)
dim(svacell) ##This has all the subjects - before the bad ones were dropped


##Add to phenotype sheet for all samples, drop your bad qc
phenoAll<-as.data.frame(RGSet@colData)
colnames(phenoAll)
phenoAll2<-cbind(phenoAll,svacell)
dim(phenoAll2)

#save after dropping dups and bad samps, not here
#we have to finish processing normalization to make sure we don't select a bad dup before dropping one dup and then selecting it.

mdatQN<-norm.quantile(mdat, method="quantile1")
mdatQN

annot<-getAnnotation(mdat)
dim(annot) ##annotation is for ~200 less probes than on the original list
##I think I am missing some probes here because the ilm10b4.hg19 annotation package is newer than when I actually ran my samples and some probes have been dropped recently
#Drop probes from here that aren't in my final dataset

remove(mdat, qcout)

betaq<-getB(mdatQN,type="Illumina",offset=100)
betaq1<-betaq[annot$Type=="I",]
betaq2<-betaq[annot$Type=="II",]


```


```{r visulaize, echo=FALSE}
###CHeck distributions again
#tiff("../PFAS_bs/preprocess_output/beta_postQN1.tiff", width = 6, height = 3, units = 'in', res = 300)
multifreqpoly(betaq,main="Multifreqpoly",xlab="Beta values, after QN", legend=FALSE)
#dev.off()

#tiff("../PFAS_bs/preprocess_output/beta_postQN2.tiff", width = 6, height = 3, units = 'in', res = 300)
multifreqpoly(betaq1,main="Multifreqpoly: Infinium I",
              xlab="Beta value, after QN", legend=FALSE)
#dev.off()

#tiff("../PFAS_bs/preprocess_output/beta_postQN3.tiff", width = 6, height = 3, units = 'in', res = 300)
multifreqpoly(betaq2,main="Multifreqpoly: Infinium II",
              xlab="Beta value, after QN", legend=FALSE)
#dev.off()

```



```{r visualize betas, echo=FALSE, fig.height=6, fig.width=10}
##Visualize distribution of betas and cluster samples by fully processed betas (betaq)
#tiff("../PFAS_bs/preprocess_output/beta_boxplots.tiff", width = 20, height = 3, units = 'in', res = 300)
boxplot(betaq)
#dev.off()


##This is slow and uses all probes
#tiff("../PFAS_bs/preprocess_output/beta_allprobes.tiff", width = 20, height = 6, units = 'in', res = 300)
plotSampleRelation(betaq, method='cluster', cv.Th=0) 
#dev.off()


 ##This is faster and uses the most variably methylated probes - whatever number is listed
#tiff("../PFAS_bs/preprocess_output/beta_sex.tiff", width = 6, height = 6, units = 'in', res = 300)
mdsPlot(betaq, numPositions = 10000, sampGroups = pheno$sex, sampNames = pheno$FamilyID, legendPos='top')
#dev.off()


#tiff("../PFAS_bs/preprocess_output/beta_round.tiff", width = 6, height = 6, units = 'in', res = 300)
mdsPlot(betaq, numPositions = 10000, sampGroups = pheno$Epic_round, sampNames = pheno$FamilyID, legendPos='topmiddle')
#dev.off()


#tiff("../PFAS_bs/preprocess_output/beta_race.tiff", width = 6, height = 6, units = 'in', res = 300)
mdsPlot(betaq, numPositions = 10000, sampGroups = pheno$race_white, sampNames = pheno$FamilyID, legendPos='top')
#dev.off()


#tiff("../PFAS_bs/preprocess_output/beta_dup.tiff", width = 6, height = 6, units = 'in', res = 300)
mdsPlot(betaq, numPositions = 10000, sampGroups = pheno$EPIC_dup, sampNames = pheno$FamilyID, legendPos='top')
#dev.off()

```

# Dealing with the Duplicated Samples

There are several samples that were duplicated - we want to make sure, that while they all passed QC, we still don't choose one to use that is poor quality. Below are some images used to see if there are any very far off. 


Family #33 looks a bit different than the rest, but on the scale, they are not terrible, especially compared to family 23 and 109. We can see how they shake out in other ways. If they continue to be very different, we can drop.



```{r drop probes with SNPs, include=FALSE}
##In the future, I could also drop multi-modal probes instead based on actual data here with ENmix
##Use this code to drop probes with known SNPs (of any MAF) within the targeted CpG or SBE position
snps<-getSnpInfo(mdatQN)
colnames(snps)

#Have to make mdat a genomic methylset
GmdatQN<-mapToGenome(mdatQN) 
GmdatQN<-addSnpInfo(GmdatQN) 
GmdatQN2<-dropLociWithSnps(GmdatQN, snps=c("SBE","CpG"), maf=0)
GmdatQN2 
```


```{r drop cross-reactive probes, include=FALSE}
# probes from Pidsley 2016 (EPIC) - much faster way to do this!
xloci <- maxprobes::xreactive_probes(array_type = "EPIC")
length(xloci)

#remove these epic probes
keepspec_xrxn<-!(rownames(GmdatQN2) %in% xloci)
GmdatQN3<-GmdatQN2[keepspec_xrxn,] 
remove(GmdatQN2, GmdatQN, betaq, betaq1, betaq2)
```


```{r remove probes that fail detection, include=FALSE}
detP <- detectionP(RGSet)
failed <- detP > 0.01
colMeans(failed) # Fraction of failed positions per sample
sum(rowMeans(failed)>0.5) # How many positions failed in >50% of samples?
failed.probes <- rownames(detP[rowMeans(failed)>0.5,])


# failed probes (those that fail detection)
keepspec_fail<-!(rownames(GmdatQN3) %in% failed.probes)
GmdatQN4<-GmdatQN3[keepspec_fail,] 

remove(GmdatQN3, mdat, mdatQN)
write.csv(failed.probes, '../PFAS_bs/preprocess_output/probes_failingdet.csv')
```

```{r list of final betas and annotation for correct set of probes here, include=FALSE}

annot<-getAnnotation(GmdatQN4)

#epic has 866,836 probes
#we have this many that passed so far:
dim(annot)
#dropped a total of ~85,000 probes
beta<-getBeta(GmdatQN4,offset=100)

```




```{r dealing with dup selection, include=FALSE}
#round 4 for family 19 looks a bit off - when we look at the hierachal plot of all samples this one is pretty far off from the rest of the group: 
#we should ID that as a "bad" sample and not randomly select it (but keep its partner for analysis)
#pull out all dups
alldups<-phenoAll2[phenoAll2$FamilyID %in% phenoAll2$FamilyID[duplicated(phenoAll2$FamilyID)], ]
alldups<-as.data.frame(alldups)
#remove bad dups
failed_qc_manual<-rbind(failed_qc_tot,
                mytargets[which(mytargets$barcode=="204365940014_R05C01"),]
                )#203013210050_R06C01 is the other maybe partner trouble

#remove bad dups
failed_qc_manual<-rbind(failed_qc_tot,
                mytargets[which(mytargets$barcode=="204365940014_R05C01"),]
                )#203013210050_R06C01 is the other maybe partner trouble

famsfailed<-failed_qc_manual$barcode 
alldups_good <-alldups[!(alldups$barcode %in% famsfailed),]

#for each pair of dups, mark one randomly as true
set.seed(123)
randomselect<-data.table(alldups_good)[,.SD[sample(1:.N,1),], by="FamilyID",] #these are the keepers!
randomselect$FamilyID #no repeats here and about half (one sample was triplicated) of the total # of dups

#grab only the unique values and bind to those we are taking from the duplicates
rows_badsamples<-!(phenoAll2$barcode %in% failed_qc_manual$barcode)
allgood <- phenoAll2[rows_badsamples,]

rows_unique<-!(allgood$barcode %in% alldups$barcode)
allunique <- allgood[rows_unique,]
finalgroup<-rbind(randomselect, allunique)
finalgroup$FamilyID #no duplicated samples and the values from duplicated are still there!
```

```{r use duplicates to drop probes that were not well replicated (not including the "bad" samples), include=FALSE}
random_barcodes<-randomselect$barcode 
nonselectdups<-alldups_good[!(alldups_good$barcode %in% random_barcodes),] #first get the two lists of the good and bad samples
matchdups<- full_join(randomselect, nonselectdups, by="FamilyID")#match the data based on family id only
barcodes_dups<-as.data.frame(cbind(matchdups$barcode.x, matchdups$barcode.y))#this is the paired barcodes now to use for subtraction
barcodes_dups<-barcodes_dups%>%drop_na("V2") #remove the ones with a missing value - this won't help us subtract

#create a blank matrix 
rw<-as.numeric(nrow(beta))
cl<-as.numeric(nrow(barcodes_dups))

dupdiff<-matrix(, nrow = rw, ncol = cl) #DONT DO THIS MORE THAN ONCE, or else it will add blank rows/cols to the matrix you already created

#now subtract the betas of V1 barcodes from V2 barcodes
for (i in 1:nrow(barcodes_dups)){
                dupdiff[,i] <- abs(beta[,eval(parse(text=paste0("barcodes_dups$V1[", i, "]")))]-
                                   beta[,eval(parse(text=paste0("barcodes_dups$V2[", i, "]")))])
                }
head(dupdiff) #looks very good

#average the rows
mean_betadiff<-rowMeans(dupdiff)

#create a logical vector of those averaging more than 5% difference
baddiff_probes_05<- ifelse(mean_betadiff >=0.05, TRUE, FALSE)

table(baddiff_probes_05)["TRUE"]
 
baddiff_probes_10<- ifelse(mean_betadiff >=0.1, TRUE, FALSE)

table(baddiff_probes_10)["TRUE"]

#for fun - lets see 2.5% and 1% too: 
baddiff_probes_01<- ifelse(mean_betadiff >=0.01, TRUE, FALSE)

table(baddiff_probes_01)["TRUE"] 
 
baddiff_probes_025<- ifelse(mean_betadiff >=0.025, TRUE, FALSE)
table(baddiff_probes_025)["TRUE"]

#we can drop the probes later - in the final run of the data

```


After some quick math, we can also see that there are some probes in the duplicated samples that were poorly replicated. For those with a more than x% difference, we see Y probes failing: 
    
    1. 1% - 551,863
    2. 2.5% - 146,281
    3. 5% - 19,640
    4. 10% - 1,659


```{r removing things, include=FALSE, warning=FALSE}
##Get rid of some of the big objects we don't need anymore
remove(alldups_bad, cl, dupsbad, i, mean_betadiff, rw, baddiff_probes_01, baddiff_probes_025, baddiff_probes_10, xloci, mdatQN)

remove(failed_qc, qcout, beta1, beta2, betaq1, betaq2, GmdatQN, GmdatQN2, GmdatQN3, GmdatQN4, betaq, detP, snps, annot, mdat, qc_sex, xloci, failed, failed.probes, failed_qc_manual, famsfailed, rows_badsamples, rows_unique, allunique, alldups_good, phenoAll, celltype, mytargets, mset)
```


# Final QC - No Duplicates

The following are the same images that were generated above, but only using the final set of families (with no duplicates) for the QC. 


```{r Quanitle normalization, redo without the dups, echo=FALSE}
#first need to add the unselected dups to the failed list.
badsamp_rows<- !(phenoAll2$barcode %in% allgood$barcode)
bad_ids<-phenoAll2$barcode[badsamp_rows]
baddups<- (alldups[!(alldups$barcode %in% randomselect$barcode),])
bad_ids2<- c(bad_ids, baddups$barcode)



mdat_nodups<-preprocessENmix(RGSet, bgParaEst = "oob", dyeCorr="RELIC", QCinfo=qcE, exQCsample=FALSE, exQCcpg=TRUE, 
                      exSample=bad_ids2, exCpG=NULL, nCores = 6) #be sure to make your list and have your computer's

mdatQN_nodups<-norm.quantile(mdat_nodups, method="quantile1")
#mdatQN_nodups

annot<-getAnnotation(mdat_nodups)
#dim(annot) 

remove(badsamp_rows, bad_ids, baddups, allgood, alldups, alldups_good, allunique, failed_qc_tot, matchdups, phenoAll2, random_barcodes, qcE, mdat_nodups)

betaq<-getB(mdatQN_nodups,type="Illumina",offset=100)
betaq1<-betaq[annot$Type=="I",]
betaq2<-betaq[annot$Type=="II",]

###CHeck distributions again
tiff("../PFAS_bs/preprocess_output/FINAL_beta_postQN1_nodups.tiff", width = 6, height = 3, units = 'in', res = 300)
multifreqpoly(betaq,main="Multifreqpoly",xlab="Beta values, after QN", legend=FALSE)
dev.off()

tiff("../PFAS_bs/preprocess_output/FINAL_beta_postQN2_nodups.tiff", width = 6, height = 3, units = 'in', res = 300)
multifreqpoly(betaq1,main="Multifreqpoly: Infinium I",
              xlab="Beta value, after QN", legend=FALSE)
dev.off()

tiff("../PFAS_bs/preprocess_output/FINAL_beta_postQN3_nodups.tiff", width = 6, height = 3, units = 'in', res = 300)
multifreqpoly(betaq2,main="Multifreqpoly: Infinium II",
              xlab="Beta value, after QN", legend=FALSE)
dev.off()

```

```{r visualize slightly adjusted betas, echo=FALSE}
##Visualize distribution of betas and cluster samples by fully processed betas (betaq)
tiff("../PFAS_bs/preprocess_output/FINALbeta_boxplots.tiff", width = 20, height = 3, units = 'in', res = 300)
boxplot(betaq)
dev.off()

##This is slow and uses all probes
tiff("../PFAS_bs/preprocess_output/FINALbeta_allprobes.tiff", width = 20, height = 6, units = 'in', res = 300)
plotSampleRelation(betaq, method='cluster', cv.Th=0) 
dev.off()

 ##This is faster and uses the most variably methylated probes - whatever number is listed
tiff("../PFAS_bs/preprocess_output/FINALbeta_sex.tiff", width = 6, height = 6, units = 'in', res = 300)
mdsPlot(betaq, numPositions = 10000, sampGroups = pheno$sex, sampNames = pheno$FamilyID, legendPos='top')
dev.off()

tiff("../PFAS_bs/preprocess_output/FINALbeta_round.tiff", width = 6, height = 6, units = 'in', res = 300)
mdsPlot(betaq, numPositions = 10000, sampGroups = pheno$Epic_round, sampNames = pheno$FamilyID, legendPos='topmiddle')
dev.off()

tiff("../PFAS_bs/preprocess_output/FINALbeta_race.tiff", width = 6, height = 6, units = 'in', res = 300)
mdsPlot(betaq, numPositions = 10000, sampGroups = pheno$race_white, sampNames = pheno$FamilyID, legendPos='top')
dev.off()

tiff("../PFAS_bs/preprocess_output/FINALbeta_dup.tiff", width = 6, height = 6, units = 'in', res = 300)
mdsPlot(betaq, numPositions = 10000, sampGroups = pheno$EPIC_dup, sampNames = pheno$FamilyID, legendPos='top')
dev.off()
```



```{r drop probes with SNPs, final time, include=FALSE}
##In the future, I could also drop multi-modal probes instead based on actual data here with ENmix
##Use this code to drop probes with known SNPs (of any MAF) within the targeted CpG or SBE position
snps<-getSnpInfo(mdatQN_nodups)
colnames(snps)

#Have to make mdat a genomic methylset
GmdatQN<-mapToGenome(mdatQN_nodups) 
GmdatQN<-addSnpInfo(GmdatQN) 
GmdatQN2<-dropLociWithSnps(GmdatQN, snps=c("SBE","CpG"), maf=0)
GmdatQN2 
```


```{r drop cross-reactive probes, final time, include=FALSE}
# probes from Pidsley 2016 (EPIC)
#remove these epic probes
GmdatQN3<-GmdatQN2[keepspec_xrxn,] 
```

```{r remove probes that fail detection, final time, include=FALSE}

# failed probes (those that fail detection)
GmdatQN4 <- GmdatQN3[keepspec_fail,]


#drop probes that were really different between duplicates
GmdatQN5<- GmdatQN4[!baddiff_probes_05,]
```

```{r list of final betas and annotation for correct set of probes here, final time, include=FALSE}
remove(betaq1, betaq2)

annot<-getAnnotation(GmdatQN5)
dim(annot)
beta<-getBeta(GmdatQN5,offset=100)

```


```{r champ,include=FALSE}
##We might use the betas (beta) for final models, or we might need to adjust for batch first
##Use the SVD function in combat here to determine whether batch and other variables are associated with the DNAm data


finalgroup<-as.data.frame(finalgroup)

#put everything in the proper order now
myorder<-as.data.frame(colnames(beta))
colnames(myorder)<- "barcode"
orderedfinalgroup<- left_join(myorder, finalgroup)



###Make sure we are using the phenotype file here with cells and SVA-PCs added
##Set up list of variables, including Array and Slide for batch, that you want to see if they contribute to 
##PCs of methylation profiles
##Also want to see the influence of all my covariates of interest on the data
##Add your exposures of interest to this list, too!
pdvars=c("Array", "Slide", "EPIC_round", "Sample_Name",'FamilyID', "Bcell", "Gran", "CD8T", "CD4T", "Mono", "NK", "nRBC", "race_white","mom_wtgain_kg","smoking_stat","Parity","marital_status",
         'BMI','no_days2deliv',"mtr_age_yrs","rod","sex","brthwt_gms", "edu", "occupation",
         "PC1","PC2","PC3","PC4","PC5")
pd_short<-orderedfinalgroup[,colnames(orderedfinalgroup) %in% pdvars]

batcheffects<-champ.SVD(beta=beta, pd=pd_short,resultsDir=paste("../PFAS_bs/preprocess_output/CHAMP.pdf"))

##Look at the output pdf and see what is associated with the PCs of the methylation data.
#If Slide and Array and highly associated, used combat to take out this variability. 
#Combat really only takes variability out of PC1 - so if they are associated with lots of PCs, we can adjust for 
#the PCs of technical variance instead in models...

#This is how you would run combat if deciding to
#betabatch<-champ.runCombat(beta=beta, pd=pdshort,batchname=c("Slide","Sample_Plate"))

##X and Y chromosome probes can be removed before analysis unless sex-stratified analyses are performed
keepauto<-!(rownames(beta) %in%annot$Name[annot$chr %in% c("chrX","chrY")])
#table(keepauto) #
betaXY<-beta[keepauto,] 
annotXY<-annot[keepauto,]


###Processing complete. Analysis can start. 
```


```{r save files, include=FALSE}
####You can save the fully processed betas, annotation file, etc as load those later instead of going through all of this again
save(beta, file ="../PFAS_bs/preprocess_output/beta.Rda")
save(orderedfinalgroup, file ="../PFAS_bs/preprocess_output/finalpheno.Rda")
save(annot, file ="../PFAS_bs/preprocess_output/annot.Rda")

save(betaXY, file ="../PFAS_bs/preprocess_output//beta_fornosex.Rda")
save(annotXY, file ="../PFAS_bs/preprocess_output/annot_fornosex.Rda")
write.csv(orderedfinalgroup, file ="../PFAS_bs/preprocess_output/pheno.csv")

baddupprobes<- GmdatQN4[baddiff_probes_05,]
dupnames<-baddupprobes@rowRanges@ranges@NAMES
write.csv(dupnames, "../PFAS_bs/preprocess_output/probes_notduplicated.csv", row.names=FALSE)
```